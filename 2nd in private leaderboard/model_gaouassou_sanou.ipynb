{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91bd4140-4d81-4df0-86e4-8b4cc884f46d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/scratch/gaoussou/MyEnvVariables/trustiiChallenge/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext lab_black\n",
    "from __future__ import print_function, division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils import data\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2276eba9-fd5b-49f9-b18d-fc5f3d641ea6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from pytorch tutorials\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "transform2 = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4689e59a-68c5-469c-984f-bbb2bea46c8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from medium https://medium.datadriveninvestor.com/covid-19-detection-in-x-ray-images-with-pytorch-5c5602b4658f\n",
    "train_Aug = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.Resize((224, 224)),\n",
    "        torchvision.transforms.RandomRotation((-20, 20)),\n",
    "        torchvision.transforms.RandomAffine(\n",
    "            0, translate=None, scale=[0.7, 1.3], shear=None, fill=0\n",
    "        ),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "test_Aug = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.Resize((224, 224)), torchvision.transforms.ToTensor()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65ebfedb-c2ec-46de-b017-2c8dfbf78d6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from https://learnopencv.com/image-classification-using-transfer-learning-in-pytorch/\n",
    "\n",
    "t_train = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
    "        transforms.RandomRotation(degrees=15),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "t_val = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(size=256),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "t_test = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(size=256),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50dd3d41-9f51-41d9-b39c-e1ce1e5a4911",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NORMAL', 'PNEUMONIA', 'COVID'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"data/train.csv\")\n",
    "df_train.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee9c2a4a-b54d-409a-8602-d9205d2ceeb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# custom function to load dataset, we can also use a folder style but this is more straigh i think ;)\n",
    "class CustomDatasetTrain(Dataset):\n",
    "    def __init__(self, csv_path, images_folder, transform=None):\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.images_folder = images_folder\n",
    "        self.transform = transform\n",
    "        self.classname = [\"NORMAL\", \"PNEUMONIA\", \"COVID\"]\n",
    "        self.class2index = {\"NORMAL\": 0, \"PNEUMONIA\": 1, \"COVID\": 2}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        filename = self.df[\"image_id\"].values[index]\n",
    "        label = self.class2index[self.df[\"label\"].values[index]]\n",
    "        image = Image.open(os.path.join(self.images_folder, filename)).convert(\"RGB\")\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed1eba6b-65a6-4fd2-bbc2-cbf11da9351a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# custom function to load dataset, we can also use a folder style but this is more straigh i think ;)\n",
    "class CustomDatasetTest(Dataset):\n",
    "    def __init__(self, csv_path, images_folder, transform=None):\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.images_folder = images_folder\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        filename = self.df[\"image_id\"].values[index]\n",
    "        image = Image.open(os.path.join(self.images_folder, filename))\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35fa893c-dd0d-4694-b661-88f3d4a19238",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = CustomDatasetTrain(\n",
    "    csv_path=\"data/train.csv\", images_folder=\"data/data/\", transform=train_Aug\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f098a1b-b391-4b80-8cd7-f350293517bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def toCuda():\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abb45420-3f83-461c-8325-0f52667bd9de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = toCuda()\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3b54f0-decd-4504-a8d2-c073ca8a63d5",
   "metadata": {},
   "source": [
    "# Freezing the weights\n",
    "for param in model.parameters():\n",
    "    param.required_grad = False\n",
    "\n",
    "\n",
    "# Replacing the final layer\n",
    "model.fc =  nn.Sequential(nn.Linear(512, 256), \n",
    "                         nn.ReLU(), \n",
    "                         nn.Dropout(p=0.5), \n",
    "                         nn.Linear(256, num_classes), \n",
    "                         nn.LogSoftmax(dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba1052d-40fb-49bd-8cd9-e178271a277e",
   "metadata": {
    "tags": []
   },
   "source": [
    "model_ft = models.mobilenet_v3_large(pretrained=True)\n",
    "\n",
    "model_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f08d7f6-7401-434d-9d3f-35d492e9b8ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=20):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch}/{num_epochs - 1}\")\n",
    "        print(\"-\" * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in [\"train\", \"val\"]:\n",
    "            if phase == \"train\":\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()  # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            # print(running_loss)\n",
    "            if phase == \"train\":\n",
    "                pass\n",
    "                # scheduler.step(running_loss)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f\"{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == \"val\" and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                scheduler.step(epoch_loss)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f\"Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s\")\n",
    "    print(f\"Best val Acc: {best_acc:4f}\")\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90231a99-9af8-49a1-86a1-4f3fb3622ba8",
   "metadata": {
    "tags": []
   },
   "source": [
    "def train_and_build(model,criterion, optimizer_ft, scheduler, num_epochs=10):\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        model.train()\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        for inputs, (images, labels) in enumerate(train_dataset_loader):\n",
    "            #print(inputs)\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer_ft.zero_grad()\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer_ft.step()\n",
    "            scheduler.step()\n",
    "                            # statistics\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "        epoch_loss = running_loss / len(train_dataset)\n",
    "        epoch_acc = running_corrects.double() / len(train_dataset)\n",
    "\n",
    "        print(f' train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23bc8b0a-b0f3-4a53-ba60-8fdece5426d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from https://learnopencv.com/image-classification-using-transfer-learning-in-pytorch/\n",
    "def trainOnly(epochs, model, optimizer, loss_criterion, train_data_loader):\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start = time.time()\n",
    "        print(\"Epoch: {}/{}\".format(epoch + 1, epochs))\n",
    "        # Set to training mode\n",
    "        model.train()\n",
    "        # Loss and Accuracy within the epoch\n",
    "        train_loss = 0.0\n",
    "        train_acc = 0.0\n",
    "        valid_loss = 0.0\n",
    "        valid_acc = 0.0\n",
    "        for i, (inputs, labels) in enumerate(train_data_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # Clean existing gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass - compute outputs on input data using the model\n",
    "            outputs = model(inputs)\n",
    "            # Compute loss\n",
    "            loss = loss_criterion(outputs, labels)\n",
    "            # Backpropagate the gradients\n",
    "            loss.backward()\n",
    "            # Update the parameters\n",
    "            optimizer.step()\n",
    "            # Compute the total loss for the batch and add it to train_loss\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            # Compute the accuracy\n",
    "            ret, predictions = torch.max(outputs.data, 1)\n",
    "            correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
    "            # Convert correct_counts to float and then compute the mean\n",
    "            acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
    "            # Compute total accuracy in the whole batch and add to train_acc\n",
    "            train_acc += acc.item() * inputs.size(0)\n",
    "            # print(\"Batch number: {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}\".format( i, loss.item(), acc.item()  ))\n",
    "        avg_train_loss = train_loss / len(train_dataset)\n",
    "        avg_train_acc = train_acc / float(len(train_dataset))\n",
    "        exp_lr_scheduler.step(avg_train_loss)\n",
    "        epoch_end = time.time()\n",
    "        print(\n",
    "            \"Epoch : {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}%\".format(\n",
    "                epoch,\n",
    "                avg_train_loss,\n",
    "                avg_train_acc * 100,\n",
    "                epoch_end - epoch_start,\n",
    "            )\n",
    "        )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a805bfa4-5e9b-4d2e-953e-75d1aeef3af5",
   "metadata": {
    "tags": []
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def trainNvalid_v2(model, optimizer, loss_criterion, epochs=25):\n",
    "    history = []\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start = time.time()\n",
    "        print(\"Epoch: {}/{}\".format(epoch + 1, epochs))\n",
    "        # Set to training mode\n",
    "        model.train()\n",
    "        # Loss and Accuracy within the epoch\n",
    "        train_loss = 0.0\n",
    "        train_acc = 0.0\n",
    "        valid_loss = 0.0\n",
    "        valid_acc = 0.0\n",
    "        for i, (inputs, labels) in enumerate(train_data_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # Clean existing gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass - compute outputs on input data using the model\n",
    "            outputs = model(inputs)\n",
    "            # Compute loss\n",
    "            loss = loss_criterion(outputs, labels)\n",
    "            # Backpropagate the gradients\n",
    "            loss.backward()\n",
    "            # Update the parameters\n",
    "            optimizer.step()\n",
    "            # Compute the total loss for the batch and add it to train_loss\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            # Compute the accuracy\n",
    "            ret, predictions = torch.max(outputs.data, 1)\n",
    "            correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
    "            # Convert correct_counts to float and then compute the mean\n",
    "            acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
    "            # Compute total accuracy in the whole batch and add to train_acc\n",
    "            train_acc += acc.item() * inputs.size(0)\n",
    "            # exp_lr_scheduler.step()\n",
    "            # print(\"Batch number: {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}\".format( i, loss.item(), acc.item()  ))\n",
    "        # Validation - No gradient tracking needed\n",
    "        with torch.no_grad():\n",
    "            # Set to evaluation mode\n",
    "            model.eval()\n",
    "            # Validation loop\n",
    "            for j, (inputs, labels) in enumerate(val_data_loader):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                # Forward pass - compute outputs on input data using the model\n",
    "                outputs = model(inputs)\n",
    "                # Compute loss\n",
    "                loss = loss_criterion(outputs, labels)\n",
    "                # Compute the total loss for the batch and add it to valid_loss\n",
    "                valid_loss += loss.item() * inputs.size(0)\n",
    "                # Calculate validation accuracy\n",
    "                ret, predictions = torch.max(outputs.data, 1)\n",
    "                correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
    "                # Convert correct_counts to float and then compute the mean\n",
    "                acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
    "                # Compute total accuracy in the whole batch and add to valid_acc\n",
    "                valid_acc += acc.item() * inputs.size(0)\n",
    "                # print(\"Validation Batch number: {:03d}, Validation: Loss: {:.4f}, Accuracy: {:.4f}\".format(j, loss.item(), acc.item()))\n",
    "        # Find average training loss and training accuracy\n",
    "        avg_train_loss = train_loss / len(train)\n",
    "        avg_train_acc = train_acc / float(len(train))\n",
    "        # Find average training loss and training accuracy\n",
    "        avg_valid_loss = valid_loss / len(valid)\n",
    "        avg_valid_acc = valid_acc / float(len(valid))\n",
    "        # exp_lr_scheduler.step()\n",
    "        history.append([avg_train_loss, avg_valid_loss, avg_train_acc, avg_valid_acc])\n",
    "        epoch_end = time.time()\n",
    "        print(\n",
    "            \"Epoch : {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}%, Validation : Loss : {:.4f}, Accuracy: {:.4f}%, Time: {:.4f}s\".format(\n",
    "                epoch,\n",
    "                avg_train_loss,\n",
    "                avg_train_acc * 100,\n",
    "                avg_valid_loss,\n",
    "                avg_valid_acc * 100,\n",
    "                epoch_end - epoch_start,\n",
    "            )\n",
    "        )\n",
    "    plt.plot(history, label=\"train\")\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb719ca-9078-45f3-b61b-ec1c6eded19e",
   "metadata": {
    "tags": []
   },
   "source": [
    "model_ft = train_and_build(model_ft, criterion, optimizer_ft, exp_lr_scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983182b4-28a8-48c9-8734-c059334ac46a",
   "metadata": {
    "tags": []
   },
   "source": [
    "model_ft = models.vgg16(pretrained=True)\n",
    "model_ft.classifier[6].in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e613c7bf-3e05-49ca-af84-7d48fa297662",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /home/gaoussou/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:00<00:00, 110MB/s] \n"
     ]
    }
   ],
   "source": [
    "model_ft = models.resnet50(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "## num_ftrs = model_ft.classifier[2].in_features\n",
    "\n",
    "# vit_model_b = models.alexnet(pretrained=True)\n",
    "# num_ftrs = vit_model_b.fc.in_features\n",
    "\n",
    "# vit_model_l = models.vit_l_16(pretrained=True)\n",
    "# num_ftrs = vit_model_l.heads.head.in_features\n",
    "# model_ft = vit_model_l\n",
    "\n",
    "# model_ft = models.vgg16(pretrained=True)\n",
    "# model_ft.classifier[6].in_features\n",
    "# Freezing the weights\n",
    "# Freeze model parameters\n",
    "# for param in model_ft.parameters():\n",
    "#    param.requires_grad = False\n",
    "\n",
    "# Replacing the final layer\n",
    "# model_ft.fc =  nn.Sequential(nn.Linear(num_ftrs, 3),   nn.LogSoftmax(dim=1))\n",
    "# model_ft.head = nn.Sequential(nn.Linear(num_ftrs, 256),nn.ReLU(),nn.Dropout(0.4),nn.Linear(256, 128),nn.ReLU(),nn.Dropout(0.5),nn.Linear(128, 3),\n",
    "# nn.LogSoftmax(dim=1),  # For using NLLLoss())\n",
    "\n",
    "# model_ft.fc = torch.nn.Linear(num_ftrs, 3)\n",
    "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
    "model_ft.fc = nn.Linear(num_ftrs, 3)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "# criterion = nn.NLLLoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# lr = 3e-5 torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0005)\n",
    "\n",
    "# Observe that all parameters are being optimized  = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=10, eps=1e-06)\n",
    "optimizer_ft = optim.Adam(model_ft.parameters())\n",
    "\n",
    "exp_lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    verbose=True, mode=\"max\", optimizer=optimizer_ft\n",
    ")\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "# exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "331c6ebf-e1b9-4795-9938-04e15ece9017",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_loader = data.DataLoader(\n",
    "    dataset=train_dataset, batch_size=256, shuffle=True\n",
    ")\n",
    "train, valid = data.random_split(\n",
    "    dataset=train_dataset,\n",
    "    generator=torch.Generator().manual_seed(42),\n",
    "    lengths=[0.8, 0.2],\n",
    ")\n",
    "train_data_loader = data.DataLoader(dataset=train, batch_size=64, shuffle=True)\n",
    "\n",
    "val_data_loader = data.DataLoader(dataset=valid, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b5c8376-a16a-4569-a013-6118ed0078ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataloaders = {\"train\": train_data_loader, \"val\": val_data_loader}\n",
    "dataset_sizes = {\"train\": len(train), \"val\": len(valid)}\n",
    "class_names = dataloaders[\"train\"].dataset.dataset.classname"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00425b02-ee1c-4d6c-84bb-20263e8031d0",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "model_ft3, history = trainNvalid_v2(  # optimizer, loss_criterion,\n",
    "    model=model_ft, loss_criterion=criterion, optimizer=optimizer_ft, epochs=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19cd4b56-8005-4fbf-94d2-f8013f882b7c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50\n",
      "Epoch : 000, Training: Loss: 0.3834, Accuracy: 84.5040%\n",
      "Epoch: 2/50\n",
      "Epoch : 001, Training: Loss: 0.1605, Accuracy: 94.4247%\n",
      "Epoch: 3/50\n",
      "Epoch : 002, Training: Loss: 0.0970, Accuracy: 96.5018%\n",
      "Epoch: 4/50\n",
      "Epoch : 003, Training: Loss: 0.0910, Accuracy: 96.6931%\n",
      "Epoch: 5/50\n",
      "Epoch : 004, Training: Loss: 0.0753, Accuracy: 97.2670%\n",
      "Epoch: 6/50\n",
      "Epoch : 005, Training: Loss: 0.0872, Accuracy: 97.1304%\n",
      "Epoch: 7/50\n",
      "Epoch : 006, Training: Loss: 0.0893, Accuracy: 97.1577%\n",
      "Epoch: 8/50\n",
      "Epoch : 007, Training: Loss: 0.0524, Accuracy: 98.2782%\n",
      "Epoch: 9/50\n",
      "Epoch : 008, Training: Loss: 0.0508, Accuracy: 98.2236%\n",
      "Epoch: 10/50\n",
      "Epoch : 009, Training: Loss: 0.0628, Accuracy: 97.6496%\n",
      "Epoch: 11/50\n",
      "Epoch : 010, Training: Loss: 0.0674, Accuracy: 97.7316%\n",
      "Epoch: 12/50\n",
      "Epoch 00012: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch : 011, Training: Loss: 0.0622, Accuracy: 97.6770%\n",
      "Epoch: 13/50\n",
      "Epoch : 012, Training: Loss: 0.0426, Accuracy: 98.4422%\n",
      "Epoch: 14/50\n",
      "Epoch : 013, Training: Loss: 0.0322, Accuracy: 98.8795%\n",
      "Epoch: 15/50\n",
      "Epoch : 014, Training: Loss: 0.0281, Accuracy: 99.0981%\n",
      "Epoch: 16/50\n",
      "Epoch : 015, Training: Loss: 0.0252, Accuracy: 98.9615%\n",
      "Epoch: 17/50\n",
      "Epoch : 016, Training: Loss: 0.0188, Accuracy: 99.3441%\n",
      "Epoch: 18/50\n",
      "Epoch : 017, Training: Loss: 0.0187, Accuracy: 99.3441%\n",
      "Epoch: 19/50\n",
      "Epoch : 018, Training: Loss: 0.0186, Accuracy: 99.4261%\n",
      "Epoch: 20/50\n",
      "Epoch : 019, Training: Loss: 0.0158, Accuracy: 99.4807%\n",
      "Epoch: 21/50\n",
      "Epoch : 020, Training: Loss: 0.0166, Accuracy: 99.2894%\n",
      "Epoch: 22/50\n",
      "Epoch : 021, Training: Loss: 0.0120, Accuracy: 99.6720%\n",
      "Epoch: 23/50\n",
      "Epoch 00023: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch : 022, Training: Loss: 0.0143, Accuracy: 99.5354%\n",
      "Epoch: 24/50\n",
      "Epoch : 023, Training: Loss: 0.0103, Accuracy: 99.7267%\n",
      "Epoch: 25/50\n",
      "Epoch : 024, Training: Loss: 0.0110, Accuracy: 99.6994%\n",
      "Epoch: 26/50\n",
      "Epoch : 025, Training: Loss: 0.0114, Accuracy: 99.6447%\n",
      "Epoch: 27/50\n",
      "Epoch : 026, Training: Loss: 0.0108, Accuracy: 99.7267%\n",
      "Epoch: 28/50\n",
      "Epoch : 027, Training: Loss: 0.0120, Accuracy: 99.6174%\n",
      "Epoch: 29/50\n",
      "Epoch : 028, Training: Loss: 0.0120, Accuracy: 99.6994%\n",
      "Epoch: 30/50\n",
      "Epoch : 029, Training: Loss: 0.0085, Accuracy: 99.7540%\n",
      "Epoch: 31/50\n",
      "Epoch : 030, Training: Loss: 0.0098, Accuracy: 99.7540%\n",
      "Epoch: 32/50\n",
      "Epoch : 031, Training: Loss: 0.0113, Accuracy: 99.6994%\n",
      "Epoch: 33/50\n",
      "Epoch : 032, Training: Loss: 0.0102, Accuracy: 99.6447%\n",
      "Epoch: 34/50\n",
      "Epoch 00034: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch : 033, Training: Loss: 0.0088, Accuracy: 99.6994%\n",
      "Epoch: 35/50\n",
      "Epoch : 034, Training: Loss: 0.0102, Accuracy: 99.8087%\n",
      "Epoch: 36/50\n",
      "Epoch : 035, Training: Loss: 0.0118, Accuracy: 99.5081%\n",
      "Epoch: 37/50\n",
      "Epoch : 036, Training: Loss: 0.0107, Accuracy: 99.7267%\n",
      "Epoch: 38/50\n",
      "Epoch : 037, Training: Loss: 0.0090, Accuracy: 99.8087%\n",
      "Epoch: 39/50\n",
      "Epoch : 038, Training: Loss: 0.0113, Accuracy: 99.6447%\n",
      "Epoch: 40/50\n",
      "Epoch : 039, Training: Loss: 0.0076, Accuracy: 99.8360%\n",
      "Epoch: 41/50\n",
      "Epoch : 040, Training: Loss: 0.0114, Accuracy: 99.6720%\n",
      "Epoch: 42/50\n",
      "Epoch : 041, Training: Loss: 0.0102, Accuracy: 99.6447%\n",
      "Epoch: 43/50\n",
      "Epoch : 042, Training: Loss: 0.0112, Accuracy: 99.7267%\n",
      "Epoch: 44/50\n",
      "Epoch : 043, Training: Loss: 0.0110, Accuracy: 99.5627%\n",
      "Epoch: 45/50\n",
      "Epoch 00045: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch : 044, Training: Loss: 0.0099, Accuracy: 99.6720%\n",
      "Epoch: 46/50\n",
      "Epoch : 045, Training: Loss: 0.0087, Accuracy: 99.7814%\n",
      "Epoch: 47/50\n",
      "Epoch : 046, Training: Loss: 0.0081, Accuracy: 99.8087%\n",
      "Epoch: 48/50\n",
      "Epoch : 047, Training: Loss: 0.0074, Accuracy: 99.8360%\n",
      "Epoch: 49/50\n",
      "Epoch : 048, Training: Loss: 0.0085, Accuracy: 99.7540%\n",
      "Epoch: 50/50\n",
      "Epoch : 049, Training: Loss: 0.0104, Accuracy: 99.7267%\n"
     ]
    }
   ],
   "source": [
    "model_ft2 = trainOnly(\n",
    "    epochs=50,\n",
    "    model=model_ft,\n",
    "    optimizer=optimizer_ft,\n",
    "    loss_criterion=criterion,\n",
    "    train_data_loader=train_dataset_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "820e6fd6-12a7-4182-8862-0cd5e3131a25",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4\n",
      "----------\n",
      "train Loss: 0.0105 Acc: 0.9966\n",
      "val Loss: 0.0087 Acc: 0.9986\n",
      "\n",
      "Epoch 1/4\n",
      "----------\n",
      "train Loss: 0.0178 Acc: 0.9952\n",
      "val Loss: 0.0062 Acc: 0.9986\n",
      "\n",
      "Epoch 2/4\n",
      "----------\n",
      "train Loss: 0.0147 Acc: 0.9959\n",
      "val Loss: 0.0072 Acc: 0.9973\n",
      "\n",
      "Epoch 3/4\n",
      "----------\n",
      "train Loss: 0.0137 Acc: 0.9952\n",
      "val Loss: 0.0069 Acc: 0.9973\n",
      "\n",
      "Epoch 4/4\n",
      "----------\n",
      "train Loss: 0.0155 Acc: 0.9952\n",
      "val Loss: 0.0111 Acc: 0.9932\n",
      "\n",
      "Training complete in 1m 40s\n",
      "Best val Acc: 0.998632\n"
     ]
    }
   ],
   "source": [
    "model_ft3 = train_model(\n",
    "    model=model_ft2,\n",
    "    optimizer=optimizer_ft,\n",
    "    criterion=criterion,\n",
    "    scheduler=exp_lr_scheduler,\n",
    "    num_epochs=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49f3fc1f-9a55-474e-93ce-2c38010527c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model_ft3.state_dict(), \"TrainingOnlyRes50Net2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dd1b0aa3-d603-4b03-89aa-14237ad6f9ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "\n",
    "test_dataset = CustomDatasetTest(\n",
    "    csv_path=\"data/test.csv\", images_folder=\"data/data/\", transform=test_Aug\n",
    ")\n",
    "test_data_loader = data.DataLoader(dataset=test_dataset, batch_size=1, shuffle=True)\n",
    "cat_to_index = {0: \"NORMAL\", 1: \"PNEUMONIA\", 2: \"COVID\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "edafbf66-fe45-4f29-a490-c3f3927d3fca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1569/1569 [00:21<00:00, 74.32it/s]\n"
     ]
    }
   ],
   "source": [
    "model_ft3.eval()\n",
    "test_data_loader = tqdm(test_data_loader)\n",
    "\n",
    "pred_list = {}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, d in enumerate(test_data_loader):\n",
    "        # print(type(d[1][0]))\n",
    "        single_im = d[0].to(device)\n",
    "        im_name = d[1]\n",
    "\n",
    "        pred = model_ft3(single_im)\n",
    "\n",
    "        _, index = torch.max(pred, 1)\n",
    "        # total += label.size(0)\n",
    "        # correct_preds += (index == label).sum().item()\n",
    "        # print(index.item(), cat_to_index[index.item()], im_name[0])\n",
    "        pred_list[im_name[0]] = cat_to_index[index.item()]\n",
    "\n",
    "df = pd.DataFrame(pred_list.items(), columns=[\"image_id\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2014aa24-44a5-42f1-984a-d403abe6caab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"data/test.csv\")\n",
    "# df_test=df_test.set_index('trustii_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2c5845eb-0d77-4b7b-8880-b08425e7ac1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_submit = df.merge(df_test, on=\"image_id\")\n",
    "df_submit = df_submit.set_index(\"trustii_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "76783a07-396f-4df9-b708-0f15765cf092",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trustii_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>7873984.png</td>\n",
       "      <td>PNEUMONIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>2220575.png</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>1208578.png</td>\n",
       "      <td>PNEUMONIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>9486255.png</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>6944127.png</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>9628080.png</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>5424375.png</td>\n",
       "      <td>PNEUMONIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>1598625.png</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7442183.png</td>\n",
       "      <td>PNEUMONIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>9809683.png</td>\n",
       "      <td>COVID</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1569 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               image_id      label\n",
       "trustii_id                        \n",
       "286         7873984.png  PNEUMONIA\n",
       "708         2220575.png     NORMAL\n",
       "1295        1208578.png  PNEUMONIA\n",
       "199         9486255.png     NORMAL\n",
       "39          6944127.png     NORMAL\n",
       "...                 ...        ...\n",
       "432         9628080.png     NORMAL\n",
       "79          5424375.png  PNEUMONIA\n",
       "350         1598625.png     NORMAL\n",
       "3           7442183.png  PNEUMONIA\n",
       "1215        9809683.png      COVID\n",
       "\n",
       "[1569 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fa76079d-a64f-4bca-ad23-8dfc546adbcf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_submit.to_csv(\"my_submission_gs_test5_resTrainOnlyft50.csv\", encoding=\"UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd85654b-4af7-4b4e-b58b-f3dcc1205cb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trustiichallenge",
   "language": "python",
   "name": "trustiichallenge"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
